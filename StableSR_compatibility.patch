diff --git a/basicsr/data/degradations.py b/basicsr/data/degradations.py
index 5db40fb..f3554b2 100644
--- a/basicsr/data/degradations.py
+++ b/basicsr/data/degradations.py
@@ -5,7 +5,7 @@ import random
 import torch
 from scipy import special
 from scipy.stats import multivariate_normal
-from torchvision.transforms.functional_tensor import rgb_to_grayscale
+from torchvision.transforms.functional import rgb_to_grayscale

 # -------------------------------------------------------------------- #
 # --------------------------- blur kernels --------------------------- #
diff --git a/ldm/models/diffusion/ddpm.py b/ldm/models/diffusion/ddpm.py
index 4664826..09300d1 100644
--- a/ldm/models/diffusion/ddpm.py
+++ b/ldm/models/diffusion/ddpm.py
@@ -16,7 +16,7 @@ from contextlib import contextmanager
 from functools import partial
 from tqdm import tqdm
 from torchvision.utils import make_grid
-from pytorch_lightning.utilities.distributed import rank_zero_only
+from pytorch_lightning.utilities.rank_zero import rank_zero_only

 from ldm.util import log_txt_as_img, exists, default, ismap, isimage, mean_flat, count_params, instantiate_from_config
 from ldm.modules.ema import LitEma
@@ -1633,25 +1633,6 @@ class LatentDiffusionSRTextWT(DDPM):
                 else:
                     param.requires_grad = True

-        print('>>>>>>>>>>>>>>>>model>>>>>>>>>>>>>>>>>>>>')
-        param_list = []
-        for name, params in self.model.named_parameters():
-            if params.requires_grad:
-                param_list.append(name)
-        print(param_list)
-        param_list = []
-        print('>>>>>>>>>>>>>>>>>cond_stage_model>>>>>>>>>>>>>>>>>>>')
-        for name, params in self.cond_stage_model.named_parameters():
-            if params.requires_grad:
-                param_list.append(name)
-        print(param_list)
-        param_list = []
-        print('>>>>>>>>>>>>>>>>structcond_stage_model>>>>>>>>>>>>>>>>>>>>')
-        for name, params in self.structcond_stage_model.named_parameters():
-            if params.requires_grad:
-                param_list.append(name)
-        print(param_list)
-
         # P2 weighting: https://github.com/jychoi118/P2-weighting
         if p2_gamma is not None:
             assert p2_k is not None
@@ -2246,7 +2227,6 @@ class LatentDiffusionSRTextWT(DDPM):
             else:
                 return self.first_stage_model.decode(z)

-    @torch.no_grad()
     def encode_first_stage(self, x):
         if hasattr(self, "split_input_params"):
             if self.split_input_params["patch_distributed_vq"]:
diff --git a/ldm/modules/encoders/modules.py b/ldm/modules/encoders/modules.py
index d2ac91a..36eb19e 100644
--- a/ldm/modules/encoders/modules.py
+++ b/ldm/modules/encoders/modules.py
@@ -150,7 +150,9 @@ class FrozenOpenCLIPEmbedder(AbstractEncoder):
                  freeze=True, layer="last"):
         super().__init__()
         assert layer in self.LAYERS
-        model, _, _ = open_clip.create_model_and_transforms(arch, device=torch.device('cpu'), pretrained=version)
+        model, _, _ = open_clip.create_model_and_transforms(arch,
+                                                            device=torch.device('cpu'),
+                                                            pretrained="/home/nskochetkov/.cache/huggingface/hub/models--laion--CLIP-ViT-H-14-laion2B-s32B-b79K/blobs/9a78ef8e8c73fd0df621682e7a8e8eb36c6916cb3c16b291a082ecd52ab79cc4")
         del model.visual
         self.model = model

